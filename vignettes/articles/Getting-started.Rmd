---
title: "Getting started"
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
suppressPackageStartupMessages(library(tidymodels))
library(tft)
```

tft is an R implementation of Temporal Fusion Transformers (TFT) using the torch package. The Temporal Fusion Transformer is a neural network architecture proposed by Bryan Lim et al. with the goal of making interpretable multi-horizon time-series forecasts.

The R package tft abstracts away the details of the architecture and
provides an API that allows easy experimenting with the TFT architecture.

In this article we will create forecasts for the `?walmart_sales_weekly` dataset included in the [walmartdata](https://github.com/dfalbel/walmartdata) package. This dataset has weekly sales of a sample of
weekly sales by department of 45 retail stores. It also includes a few external predictors like the temperature,
fuel price and the size of the store.

```{r}
data(walmart_sales, package = "walmartdata")
dplyr::glimpse(walmart_sales)
```

To make the example faster to run, we are going to create models for the first 2
stores.

```{r}
walmart_sales <- walmart_sales %>% 
  filter(Store %in% c(1, 2), Dept %in% c(1,2))
```


## Preparing the data

The first thing we need to make sure is that our dataset doesn't have [implicit missing observations](https://r4ds.hadley.nz/missing-values.html#missing-values). This happens when an observations is just not present in
the data instead of being explicitly marked with a `NA`. We are going to use
`tsibble` functionality to add the implicitly missing observations, but you could
use whatever tool you prefer for the task.

```{r}
sales <- walmart_sales %>%
    tsibble::tsibble(
      key = c(Store, Dept, Type, Size),
      index = Date
    ) %>%
    tsibble::group_by_key() %>%
    tsibble::fill_gaps(
      Weekly_Sales = 0,
      IsHoliday = FALSE
    ) %>%
    tidyr::fill(Size, Temperature, Fuel_Price, CPI, Unemployment, .direction = "down")
```

tft can treat columns in the dataset differently depending on their types. There
are mainly 5 types of columns:

- **'index'**: is a single date column that specifies at which point in time 
  the observation refers to. This is not directly used by the model itself, but is
  used internally to create rolling windows and order observations.
- **'key'**: are groups of columns that identify a single time series. Keys
  are necessary if you are creating predictions for multiple time series in a 
  single model. By default, 'keys' are considered 'static' predictors by the model.
- **'static'**: predictors are considered 'static' when they don't vary over time,
  they are information from the time-series, like a region or a kind of product.
- **'unknown'** are predictors that vary over time but we only know values observed
  for past observations. For example, you can use the daily temperature as a predictor,
  but you only know it for past observations.
- **'known'** are predictors that vary over time and are known even for future observations.
  For example, the day of the week can be used as a predictor for a daily time series,
  and it's known for every time step, no matter if it's from past or future.

The `recipes` package is used to specify how the model should treat each column
of the dataset.

```{r}
rec <- recipe(Weekly_Sales ~ ., data = sales) %>% 
  update_role(Date, new_role = "index") %>% 
  update_role(Store, Dept, Type, Size, new_role = "key") %>% 
  update_role(IsHoliday, new_role = "known") %>% 
  step_date(Date, role = "known", features = c("year", "month", "doy")) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_indicate_na(starts_with("MarkDown")) %>% 
  step_impute_mean(starts_with("Markdown")) %>% 
  step_include_roles()
```

It's recommended to include features that represent seasonality as known predictors
in the TFT model, like mon, day of the week and etc.
It's also recommended to normalize the predictors and treat missing values as
the model don't treat them implicitly. 

You can bake `prep` and `juice` the recipe to see how the transformations are working:

```{r}
rec %>% prep() %>% juice() %>% glimpse()
```

## Metrics and validation

Now we should think about the size of the horizon we want to create forecasts to.
It could be a single week ahead or ten, and this will influence how we split our
data for training, validation and testing. This is not really a data analysis
decision but more of a business decision, ie: how many weeks ahead we want know
so we can plan the demand and etc. Let's say we want 4 weeks ahead, ie ~1 month.

The [rsample](https://github.com/tidymodels/rsample) package provides `sliding_*`
functions that are very useful for the task of creating time splits.

```{r}
resamples <- sliding_period(
  arrange(sales, Date),
  index = Date,
  period = "week",
  lookback = Inf,
  assess_stop = 4,
  step = 4,
  skip = 104
)
```

Now we can separate the splits in, training and testing, ie: a few of them will
be used for cross-validation and choosing the hyperparamerters, the others are 
used for testing the model. We are going to use the last 4 splits for testing and 
the first 5 to cross validate.

```{r}
train_splits <- resamples %>% 
  slice(1:5) %>% 
  structure(class = "rset")
test_splits <- resamples %>% 
  slice(-c(1:5)) %>% 
  structure(class = "rset")
```

**Note**: we have selected 4 weeks as the horizon of our predictions. We need to
use this same value when specifying the horizon for the tft model.

## Fitting the model

We can now tune the tft model and compute metrics using:

```{r, eval = TRUE}
tft_model <- temporal_fusion_transformer(
  horizon = 4, 
  lookback = 100, 
  hidden_state_size = tune()
) %>% 
  set_engine("torch", verbose = FALSE) %>% 
  set_mode("regression")


model <- workflow() %>% 
  add_recipe(rec) %>% 
  add_model(tft_model)

grid <- tibble::tibble(
  hidden_state_size = c(4, 16, 32)
)

results <- tune_grid(
  model,
  resamples = train_splits,
  grid = grid,
  control = control_grid(verbose = TRUE)
)

autoplot(results)
```

Once you are happy with the tuning you can finalize the workflow and
obtain the metrics for the test splits.

```{r, eval = TRUE}
final_params <- select_best(results, metric = "rmse")
model <- finalize_workflow(model, final_params)
results <- fit_resamples(model, test_splits)
collect_metrics(results)
```

To obtain predictions for future observations, first we need to load a 
data.frame that includes known predictors like the `IsHoliday` variable
for all time steps in the future data frame. Then we can call `forecast`
or `predict` to obtain the predictions for the future data.

Note that `forecast` or `predict` currently can only predict for 
`horizon` time steps ahead. And don't provide a away for doing 
rolling forecasts.

```{r, eval = TRUE}
new_data <- walmartdata::walmart_sales_test %>% 
  filter(Store %in% c(1, 2), Dept %in% c(1,2)) %>% 
  filter(Date <= lubridate::ymd("2012-11-23"))

final_model <- fit(model, sales)
final_predictions <- predict(final_model, new_data = new_data)
final_predictions
```
