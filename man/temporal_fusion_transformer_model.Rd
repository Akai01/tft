% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tft-layers.R
\name{temporal_fusion_transformer_model}
\alias{temporal_fusion_transformer_model}
\title{Temporal Fusion Transformer Module}
\usage{
temporal_fusion_transformer_model(
  num_features,
  feature_sizes,
  hidden_state_size = 100,
  dropout = 0.1,
  num_heads = 4,
  num_lstm_layers = 2,
  num_quantiles = 3
)
}
\arguments{
\item{feature_sizes}{The number of unique elements for each categorical
variable in the dataset.}

\item{hidden_state_size}{The size of the model shared accross multiple parts
of the architecture.}

\item{dropout}{Dropout rate used in many different places in the network}

\item{num_heads}{Number of heads in the attention layer.}

\item{num_lstm_layers}{Number of LSTM layers used in the Locality Enhancement
Layer. Usually 2 is good enough.}

\item{n_features}{a list containing the shapes for all necessary information
to define the size of layers, including:
- \verb{$encoder$past$(num|cat)}: shape of past features
- \verb{$encoder$static$(num|cat)}: shape of the static features
- \verb{$decoder$target}: shape of the target variable
We exclude the batch dimension.}
}
\description{
Temporal Fusion Transformer Module
}
