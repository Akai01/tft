% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit.R, R/parsnip.R
\name{tft}
\alias{tft}
\alias{tft_config}
\alias{temporal_fusion_transformer}
\title{Temporal Fusion Transformer}
\usage{
tft(x, ...)

tft_config(
  lookback,
  horizon,
  input_types,
  subsample = 1,
  hidden_state_size = 16,
  num_attention_heads = 4,
  num_lstm_layers = 2,
  dropout = 0.1,
  batch_size = 256,
  epochs = 5,
  optimizer = "adam",
  learn_rate = 0.01,
  learn_rate_decay = c(0.1, 5),
  gradient_clip_norm = 0.1,
  quantiles = c(0.1, 0.5, 0.9),
  num_workers = 0,
  callbacks = list(),
  verbose = FALSE
)

temporal_fusion_transformer(
  mode = "regression",
  lookback = NULL,
  horizon = NULL,
  hidden_state_size = NULL,
  dropout = NULL,
  learn_rate = NULL,
  batch_size = NULL,
  epochs = NULL
)
}
\arguments{
\item{x}{A recipe or data.frame that will be used to train the model.}

\item{...}{Additional arguments passed to \code{\link[=tft_config]{tft_config()}}.}

\item{lookback}{Number of timesteps that are used as historic data for
prediction.}

\item{horizon}{Number of timesteps ahead that will be predicted by the
model.}

\item{input_types}{A list with the elements \code{index}, \code{keys}, \code{static}, \code{known} and
\code{unknown}. It's recommended to use \code{\link[=covariates_spec]{covariates_spec()}} to create it. Each element
should be a character vector containing the names of
the columns that are used for each role in the TFT model. \code{index} must be a date
column and \code{keys} are columns that allow one to identidy each time-series.
\code{index} and \code{keys} must be specified. If a column that exists in the data.frame
doesn't appear in this list, then it's considered \code{unknown}.}

\item{subsample}{Subsample from all possible slices. An integer with the number
of samples or a proportion.}

\item{hidden_state_size}{Hidden size of network which is its main hyperparameter
and can range from 8 to 512. It's also known as \code{d_model} across the paper.}

\item{num_attention_heads}{Number of attention heads in the Multi-head attention layer.
The paper refer to it as \code{m_H}. \code{4} is a good default.}

\item{num_lstm_layers}{Number of LSTM layers used in the Locality Enhancement
Layer. Usually 2 is good enough.}

\item{dropout}{Dropout rate used in many places in the architecture.}

\item{batch_size}{How many samples per batch to load.}

\item{epochs}{Maximum number of epochs for training the model.}

\item{optimizer}{Optimizer used for training. Can be a string with 'adam', 'sgd',
or 'adagrad'. Can also be a \code{\link[torch:optimizer]{torch::optimizer()}}.}

\item{learn_rate}{Leaning rate used by the optimizer.}

\item{learn_rate_decay}{Decrease the learning rate by this factor each epoch.
Can also be a vector with 2 elements. In this case we decrease the learning by
the \code{x[1]} every \code{x[2]} epochs - (where \code{x} is the \code{learn_rate_decay} vector.)
Use \code{FALSE} or any negative number to disable.}

\item{gradient_clip_norm}{Maximum norm of the gradients. Passed on to
\code{\link[luz:luz_callback_gradient_clip]{luz::luz_callback_gradient_clip()}}. If <= 0 or \code{FALSE} then no gradient
clipping is performed.}

\item{quantiles}{A numeric vector with 3 quantiles for the quantile loss.
The first is treated as lower bound of the interval, the second as the
point prediction and the thir as the upper bound.}

\item{num_workers}{Number of parallel workers for preprocessing data.}

\item{callbacks}{Additional callbacks passed when fitting the module with
luz.}

\item{verbose}{Logical value stating if the model should produce status
outputs, like a progress bar, during training.}

\item{mode}{A single character string for the type of model.
The only possible value for this model is "regression".}
}
\value{
A list with the configuration parameters.
}
\description{
Temporal Fusion Transformer

Configuration for the Temporal Fusion Transformer network
}
\section{Functions}{
\itemize{
\item \code{tft_config}: Configuration configuration options for tft.

\item \code{temporal_fusion_transformer}: Parsnip wrappers for TFT.
}}

\seealso{
\code{\link[=predict.tft]{predict.tft()}} for how to create predictions.
}
